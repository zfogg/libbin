name: Performance Benchmarks

on:
  push:
    branches: [ master, main ]
  pull_request:
    branches: [ master, main ]
  workflow_dispatch: # Allow manual triggering

env:
  CSTD: c2x
  MAKEFLAGS: "-j"

jobs:
  benchmark:
    name: Performance Benchmark
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install dependencies
      uses: ./.github/actions/install-dependencies
      with:
        os: ubuntu
        extra-packages: 'time'

    - name: Build optimized version
      run: |
        # Build library and test binary with release optimization
        make tests-release

    - name: Run performance tests
      run: |
        echo "=== Performance Benchmark Results ==="
        echo "Testing constraint-compliant vs standard implementations..."

        # Time the test execution
        echo "## Test Suite Performance"
        /usr/bin/time -v ./bin/bin_tests_release 2>&1 | tee benchmark_results.txt

        echo "## Memory Usage Analysis"
        echo "Binary sizes:"
        ls -lh build/libbin_release.so bin/bin_tests_release

        echo "## Library Metrics"
        echo "Source lines of code:"
        find src/ -name "*.c" -exec wc -l {} + | tail -1
        echo "Header lines of code:"
        find src/ -name "*.h" -exec wc -l {} + | tail -1
        echo "Test lines of code:"
        find test/ -name "*.c" -exec wc -l {} + | tail -1

    - name: Analyze benchmark results
      run: |
        echo "=== Analysis ==="

        # Extract key metrics
        if grep -q "User time" benchmark_results.txt; then
          USER_TIME=$(grep "User time" benchmark_results.txt | awk '{print $4}')
          SYSTEM_TIME=$(grep "System time" benchmark_results.txt | awk '{print $4}')
          MAX_MEMORY=$(grep "Maximum resident set size" benchmark_results.txt | awk '{print $6}')

          echo "Execution time: ${USER_TIME}s user, ${SYSTEM_TIME}s system"
          echo "Peak memory usage: ${MAX_MEMORY}KB"
        fi

        # Check if all tests passed
        if grep -q "ü•≥ Pass ALL the tests üéä.*pass" benchmark_results.txt; then
          echo "‚úÖ All tests passed successfully"
        else
          echo "‚ùå Some tests failed"
          echo ""
          echo "=== FAILED TEST OUTPUT ==="
          cat benchmark_results.txt
          echo ""
          echo "=== END FAILED TEST OUTPUT ==="
          exit 1
        fi

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results
        path: benchmark_results.txt
        retention-days: 30

    - name: Comment on PR (if applicable)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          try {
            const benchmarkResults = fs.readFileSync('benchmark_results.txt', 'utf8');

            // Extract key metrics for PR comment
            const userTimeMatch = benchmarkResults.match(/User time \(seconds\): ([\d.]+)/);
            const memoryMatch = benchmarkResults.match(/Maximum resident set size \(kbytes\): (\d+)/);

            const userTime = userTimeMatch ? userTimeMatch[1] : 'N/A';
            const maxMemory = memoryMatch ? memoryMatch[1] : 'N/A';

            const comment = `## üìä Performance Benchmark Results

            - **Execution time:** ${userTime}s
            - **Peak memory:** ${maxMemory}KB
            - **All tests:** ‚úÖ Passed

            <details>
            <summary>Full benchmark output</summary>

            \`\`\`
            ${benchmarkResults}
            \`\`\`
            </details>`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
          } catch (error) {
            console.log('Could not post benchmark results:', error);
          }